{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from helper_func import n_random_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(41)\n",
    "sc.settings.verbosity = 0\n",
    "RANDOM_SEED = 110011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading a h5ad data file...\n",
      "Clipping the adata due to the memory limitation...\n",
      "Sets of samples for severe/critical:  {0: array(['S-S069-3_severe/critical', 'S-S032-2_severe/critical',\n",
      "       'S-S072-1_severe/critical', 'S-S022-3_severe/critical',\n",
      "       'S-S005-2_severe/critical', 'S-S028_severe/critical',\n",
      "       'S-S081_severe/critical', 'S-S007-1_severe/critical',\n",
      "       'S-S045_severe/critical', 'S-S071-2_severe/critical',\n",
      "       'S-S086-2_severe/critical', 'S-S046_severe/critical',\n",
      "       'S-S066_severe/critical', 'S-S004-2_severe/critical',\n",
      "       'S-S072-3_severe/critical', 'S-S007-2_severe/critical',\n",
      "       'S-S002_severe/critical', 'S-S048_severe/critical',\n",
      "       'S-S042_severe/critical', 'S-S040_severe/critical',\n",
      "       'S-S059_severe/critical', 'S-S035-2_severe/critical',\n",
      "       'S-S011-2_severe/critical', 'S-S088-1_severe/critical',\n",
      "       'S-S072-2_severe/critical', 'S-S091_severe/critical',\n",
      "       'S-S074-1_severe/critical', 'S-S067_severe/critical',\n",
      "       'S-S053_severe/critical', 'S-S073-1_severe/critical',\n",
      "       'S-S092_severe/critical', 'S-S065_severe/critical',\n",
      "       'S-S085-1_severe/critical', 'S-S063_severe/critical',\n",
      "       'S-S009_severe/critical', 'S-S032-1_severe/critical',\n",
      "       'S-S021-1_severe/critical', 'S-S034_severe/critical',\n",
      "       'S-S036-1_severe/critical', 'S-S064_severe/critical',\n",
      "       'S-S070-1_severe/critical', 'S-S038_severe/critical',\n",
      "       'S-S014_severe/critical', 'S-S076-1_severe/critical',\n",
      "       'S-S006_severe/critical', 'S-S088-2_severe/critical',\n",
      "       'S-S044_severe/critical', 'S-S075-2_severe/critical',\n",
      "       'S-S051_severe/critical', 'S-S090-1_severe/critical',\n",
      "       'S-S029_severe/critical', 'S-S055_severe/critical',\n",
      "       'S-S020_severe/critical', 'S-S084_severe/critical',\n",
      "       'S-S021-3_severe/critical', 'S-S032-3_severe/critical',\n",
      "       'S-S069-2_severe/critical', 'S-S022-5_severe/critical',\n",
      "       'S-S087-2_severe/critical', 'S-S069-1_severe/critical'],\n",
      "      dtype=object)}\n",
      "Sets of samples for mild/moderate:  {0: array(['S-M061-2_mild/moderate', 'S-M060-2_mild/moderate',\n",
      "       'S-M063-2_mild/moderate', 'S-M036-1_mild/moderate',\n",
      "       'S-M076-1_mild/moderate', 'S-M007-5_mild/moderate',\n",
      "       'S-M011_mild/moderate', 'S-M023_mild/moderate',\n",
      "       'S-M078_mild/moderate', 'S-M034_mild/moderate',\n",
      "       'S-M007-2_mild/moderate', 'S-M056_mild/moderate',\n",
      "       'S-M061-1_mild/moderate', 'S-M009-4_mild/moderate',\n",
      "       'S-M019_mild/moderate', 'S-M007-3_mild/moderate',\n",
      "       'S-M024_mild/moderate', 'S-M028_mild/moderate',\n",
      "       'S-M026-1_mild/moderate', 'S-M009-6_mild/moderate',\n",
      "       'S-M003-3_mild/moderate', 'S-M052_mild/moderate',\n",
      "       'S-M058-1_mild/moderate', 'S-M045_mild/moderate',\n",
      "       'S-M017_mild/moderate', 'S-M004-6_mild/moderate',\n",
      "       'S-M026-3_mild/moderate', 'S-M076-2_mild/moderate',\n",
      "       'S-M013_mild/moderate', 'S-M010-3_mild/moderate',\n",
      "       'S-M014_mild/moderate', 'S-M009-5_mild/moderate',\n",
      "       'S-M038_mild/moderate', 'S-M064_mild/moderate',\n",
      "       'S-M015_mild/moderate', 'S-M031-1_mild/moderate',\n",
      "       'S-M009-2_mild/moderate', 'S-M062-2_mild/moderate',\n",
      "       'S-M043-2_mild/moderate', 'S-M003-1_mild/moderate',\n",
      "       'S-M042-1_mild/moderate', 'S-M059-2_mild/moderate',\n",
      "       'S-M010-1_mild/moderate', 'S-M009-1_mild/moderate',\n",
      "       'S-M069_mild/moderate', 'S-M030_mild/moderate',\n",
      "       'S-M004-4_mild/moderate', 'S-M032_mild/moderate',\n",
      "       'S-M073_mild/moderate', 'S-M008-2_mild/moderate',\n",
      "       'S-M041-1_mild/moderate', 'S-M005_mild/moderate',\n",
      "       'S-M007-1_mild/moderate', 'S-M040-1_mild/moderate',\n",
      "       'S-M053_mild/moderate', 'S-M050_mild/moderate',\n",
      "       'S-M021_mild/moderate', 'S-M010-2_mild/moderate',\n",
      "       'S-M043-1_mild/moderate', 'S-M010-6_mild/moderate'], dtype=object)}\n",
      "Sets of samples for control:  {0: array(['S-HC019-1_control', 'S-HC014_control', 'S-HC020-2_control',\n",
      "       'S-HC018-2_control', 'S-HC018-1_control', 'S-HC016_control',\n",
      "       'S-HC008_control', 'S-HC001_control', 'S-HC019-2_control',\n",
      "       'S-HC022_control', 'S-HC002_control', 'S-HC021_control',\n",
      "       'S-HC023_control', 'S-HC004_control', 'S-HC017_control',\n",
      "       'S-HC024_control', 'S-HC003_control', 'S-HC020-1_control',\n",
      "       'S-HC009_control', 'S-HC006_control', 'S-HC010_control',\n",
      "       'S-HC015_control', 'S-HC011_control', 'S-HC013_control',\n",
      "       'S-HC025_control', 'S-HC007_control', 'S-HC012_control',\n",
      "       'S-HC005_control'], dtype=object)}\n",
      "-------------0st data sampling------------\n"
     ]
    }
   ],
   "source": [
    "# Read adata\n",
    "num_dataset_sampling=1\n",
    "num_kfold=1\n",
    "print(\"Reading a h5ad data file...\")\n",
    "adata = sc.read_h5ad('../../data/GSE_158055_COVID19_ALL.h5ad')\n",
    "\n",
    "# Delete objects to prepare for splitting the adata to train and test.\n",
    "del adata.uns['neighbors']\n",
    "del adata.uns['pca']\n",
    "del adata.obsm['X_pca']\n",
    "del adata.obsm['X_tsne']\n",
    "del adata.obsp\n",
    "\n",
    "# Change the type of the sampleID and CoVID-19 severity to string.\n",
    "adata.obs['sampleID'] = adata.obs['sampleID'].astype('str')\n",
    "adata.obs['CoVID-19 severity'] = adata.obs['CoVID-19 severity'].astype('str')\n",
    "\n",
    "# Make a new column that has the combined information of the sampleID and CoVID-19 severity.\n",
    "adata.obs['sampleID_label'] = adata.obs['sampleID'] + '_' + adata.obs['CoVID-19 severity']\n",
    "\n",
    "# Dataset class distribution: “severe/critical” : 134, “mild/moderate”: 122, and “control”: 28.\n",
    "print(\"Clipping the adata due to the memory limitation...\")\n",
    "max_samples_covid = 60\n",
    "max_samples_control = 28 # There is only 28 control samples.\n",
    "k_sets_samples_severe_critical, k_set_samples_mild_moderate, k_sets_samples_control = \\\n",
    "                                                                n_random_sampling(adata, num_dataset_sampling, max_samples_covid, max_samples_control, RANDOM_SEED)\n",
    "                                                                \n",
    "print(\"Sets of samples for severe/critical: \", k_sets_samples_severe_critical)\n",
    "print(\"Sets of samples for mild/moderate: \", k_set_samples_mild_moderate)\n",
    "print(\"Sets of samples for control: \", k_sets_samples_control)\n",
    "\n",
    "i = 0\n",
    "print(f'-------------{i}st data sampling------------')                                            \n",
    "# Filter out adata by the k selected samples' group.\n",
    "adata = adata[adata.obs['sampleID_label'].isin(k_sets_samples_severe_critical[i]) \\\n",
    "                                            | adata.obs['sampleID_label'].isin(k_set_samples_mild_moderate[i]) \\\n",
    "                                            | adata.obs['sampleID_label'].isin(k_sets_samples_control[i])]\n",
    "# Run assert test for concatenated adata.\n",
    "assert all(adata.obs['sampleID_label'].isin(k_sets_samples_severe_critical[i]) \\\n",
    "                                            | adata.obs['sampleID_label'].isin(k_set_samples_mild_moderate[i]) \\\n",
    "                                            | adata.obs['sampleID_label'].isin(k_sets_samples_control[i]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=0 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "Started at:  1678713982.314947\n",
      "k_fold cross validation sets (split randomly for train and test) 0  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3308113/78299593.py:20: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0th adata in PCA rep to a h5ad file...\n",
      "Ended at:  1678714552.1647053\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "Started at:  1678714552.1647553\n",
      "k_fold cross validation sets (split randomly for train and test) 0  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0th adata in UMAP rep to a h5ad file...\n",
      "Ended at:  1678715621.2335327\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 110011\n",
    "k=0\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=0).\n",
    "    start_time = time.time()\n",
    "    print('Started at: ', start_time)\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')\n",
    "    \n",
    "    print('Ended at: ', time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=1 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 1  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 1  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1234\n",
    "k=1\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=1)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=2 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 2  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4150989/197565163.py:19: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 2  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1235\n",
    "k=2\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=2)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 3  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358219/2650027277.py:19: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 3th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 3  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 3th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 2222\n",
    "k=3\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=2)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 4  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_871113/206868120.py:19: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 4th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 4  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 123445\n",
    "k=4\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=2)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_scanpy_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
