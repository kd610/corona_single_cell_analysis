{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate split training and test dataset for k-fold cross validation with Differential Privacy\n",
    "\n",
    "Due to limited memory in a machine, we must divide the dataset into training and test datasets and save them with the .h5ad extension. Since we apply k-fold cross-validation, there will be k datasets for training and testing; thus, the total number of split datasets is 10 (5 for training and 5 for testing). <br><br>\n",
    "\n",
    "Apply Differential Privacy as adding laplace noise to the `adata.X`. This achieves (ε, 0)-DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import default_rng\n",
    "from scipy.stats import laplace\n",
    "\n",
    "\n",
    "np.random.seed(41)\n",
    "sc.settings.verbosity = 0\n",
    "RANDOM_SEED = 110011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_random_sampling(adata, n=1, max_samples_covid=128, max_samples_control=28, RANDOM_SEED=110011):\n",
    "    # Set the maximum number of samples for each severity group\n",
    "    max_samples_covid = max_samples_covid\n",
    "    max_samples_control = max_samples_control\n",
    "    \n",
    "    # Get the samples for each severity group\n",
    "    severe_critical_samples = adata.obs[adata.obs['CoVID-19 severity'] == 'severe/critical']['sampleID_label'].unique()\n",
    "    mild_moderate_samples = adata.obs[adata.obs['CoVID-19 severity'] == 'mild/moderate']['sampleID_label'].unique()\n",
    "    control_samples = adata.obs[adata.obs['CoVID-19 severity'] == 'control']['sampleID_label'].unique()\n",
    "\n",
    "    # Get lists of all the samples for each fold\n",
    "    # key: fold number, value: list of samples\n",
    "    k_sets_samples_severe_critical = dict() \n",
    "    k_set_samples_mild_moderate = dict()\n",
    "    k_sets_samples_control = dict()\n",
    "    \n",
    "    for i in range(n):\n",
    "        rng = default_rng(seed=RANDOM_SEED)\n",
    "        # Randomly select max_samples samples for each severity group\n",
    "        clip_samples_severe_critical = rng.choice(a=severe_critical_samples, size=max_samples_covid, replace=False, shuffle=True)\n",
    "        clip_samples_mild_moderate = rng.choice(a=mild_moderate_samples, size=max_samples_covid, replace=False, shuffle=True)\n",
    "        clip_samples_control = rng.choice(a=control_samples, size=max_samples_control, replace=False, shuffle=True) # There are only 28 control samples.\n",
    "        \n",
    "        k_sets_samples_severe_critical[i] = clip_samples_severe_critical\n",
    "        k_set_samples_mild_moderate[i] = clip_samples_mild_moderate\n",
    "        k_sets_samples_control[i] = clip_samples_control\n",
    "    \n",
    "    # Make assert if each value of k_sets_samples_severe_critical are the same.\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if set(k_sets_samples_severe_critical[i]) == set(k_sets_samples_severe_critical[j]):\n",
    "                raise AssertionError(\"Not all values in k_sets_samples_severe_critical are the same\")\n",
    "                \n",
    "    # Make assert if each value of k_set_samples_mild_moderate are the same.\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if set(k_set_samples_mild_moderate[i]) == set(k_set_samples_mild_moderate[j]):\n",
    "                raise AssertionError(\"Not all values in k_set_samples_mild_moderate are the same\")\n",
    "\n",
    "    return k_sets_samples_severe_critical, k_set_samples_mild_moderate, k_sets_samples_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_DP(X, epsilon):\n",
    "    '''\n",
    "    Apply differential privacy to the data\n",
    "    X: numpy array\n",
    "    sensitivity: float\n",
    "    epsilon: float\n",
    "    return: numpy array\n",
    "    '''\n",
    "    print(\"Start applying DP...\")\n",
    "    # Sensitivity calculation (cell-level)\n",
    "    sensitivity = np.max(np.sum(X, axis=1))\n",
    "    print(\"Sensitivity: \", sensitivity)\n",
    "    print(\"Epsilon: \", epsilon)\n",
    "    # Laplace noise scale parameter (cell-level)\n",
    "    scale_cells = sensitivity / epsilon\n",
    "\n",
    "    # Generate Laplace noise\n",
    "    laplace_noise = laplace.rvs(scale=scale_cells, size=X.shape)\n",
    "    # Apply input perturbation\n",
    "    perturbed_matrix = X + laplace_noise\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return perturbed_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading a h5ad data file...\n"
     ]
    }
   ],
   "source": [
    "# Read adata\n",
    "num_dataset_sampling=1\n",
    "num_kfold=1\n",
    "print(\"Reading a h5ad data file...\")\n",
    "adata = sc.read_h5ad('./data/GSE_158055_COVID19_ALL.h5ad')\n",
    "\n",
    "# Delete objects to prepare for splitting the adata to train and test.\n",
    "del adata.uns['neighbors']\n",
    "del adata.uns['pca']\n",
    "del adata.obsm['X_pca']\n",
    "del adata.obsm['X_tsne']\n",
    "del adata.obsp\n",
    "\n",
    "# Change the type of the sampleID and CoVID-19 severity to string.\n",
    "adata.obs['sampleID'] = adata.obs['sampleID'].astype('str')\n",
    "adata.obs['CoVID-19 severity'] = adata.obs['CoVID-19 severity'].astype('str')\n",
    "\n",
    "# Make a new column that has the combined information of the sampleID and CoVID-19 severity.\n",
    "adata.obs['sampleID_label'] = adata.obs['sampleID'] + '_' + adata.obs['CoVID-19 severity']\n",
    "\n",
    "# Dataset class distribution: “severe/critical” : 134, “mild/moderate”: 122, and “control”: 28.\n",
    "print(\"Clipping the adata due to the memory limitation...\")\n",
    "max_samples_covid = 60\n",
    "max_samples_control = 28 # There is only 28 control samples.\n",
    "k_sets_samples_severe_critical, k_set_samples_mild_moderate, k_sets_samples_control = \\\n",
    "                                                                n_random_sampling(adata, num_dataset_sampling, max_samples_covid, max_samples_control, RANDOM_SEED)\n",
    "                                                                \n",
    "print(\"Sets of samples for severe/critical: \", k_sets_samples_severe_critical)\n",
    "print(\"Sets of samples for mild/moderate: \", k_set_samples_mild_moderate)\n",
    "print(\"Sets of samples for control: \", k_sets_samples_control)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=0 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "Start applying DP...\n",
      "Sensitivity:  8696.728\n",
      "Epsilon:  0.1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 110011\n",
    "k=0\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Apply DP\n",
    "    adata.X = apply_DP(adata.X, epsilon=1.0)\n",
    "    \n",
    "    # Create adata for train and test (k=0).\n",
    "    start_time = time.time()\n",
    "    print('Started at: ', start_time)\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19_DP.h5ad')\n",
    "    \n",
    "    print('Ended at: ', time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=1 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 1  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 1  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 1th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1234\n",
    "k=1\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=1)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=2 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 2  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4150989/197565163.py:19: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 2  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1235\n",
    "k=2\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=2)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=3 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 3  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358219/2650027277.py:19: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 3th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 3  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 3th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 2222\n",
    "k=3\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=2)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_concat\n",
    "del adata_train\n",
    "del adata_test\n",
    "\n",
    "# Drop the column of contain_y_train and contain_y_test from adata.obs\n",
    "adata.obs.drop(columns=['contain_y_train', 'contain_y_test'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adata_train and adata_test for k=4 in k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Using an input representation:  X_pca  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 4  on the  0 st clipped dataset --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_871113/206868120.py:19: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 4th adata in PCA rep to a h5ad file...\n",
      "----------------Using an input representation:  X_umap  ------------------\n",
      "k_fold cross validation sets (split randomly for train and test) 4  on the  0 st clipped dataset --------\n",
      "Run PCA and UMAP on the adata_train.\n",
      "Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dozonok/anaconda3/envs/workshop_scanpy_2/lib/python3.8/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 4th adata in UMAP rep to a h5ad file...\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 123445\n",
    "k=4\n",
    "\n",
    "for rep in ['X_pca', 'X_umap']:\n",
    "    print(\"----------------Using an input representation: \", rep, \" ------------------\")\n",
    "    if rep == 'X_umap':\n",
    "        rep_name = 'UMAP'\n",
    "    else:\n",
    "        rep_name = 'PCA'\n",
    "\n",
    "    # Create adata for train and test (k=2)\n",
    "    start_time = time.time()\n",
    "    print(\"k_fold cross validation sets (split randomly for train and test)\", k, \" on the \", i, \"st clipped dataset\",\"--------\")\n",
    "    list_samples = list(adata.obs['sampleID_label'].unique())\n",
    "    y_train, y_test = train_test_split(list_samples, test_size=0.20, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_train'] = adata.obs['sampleID_label'].isin(y_train)\n",
    "    adata_train = adata[adata.obs['contain_y_train'] == True,:].copy()\n",
    "    # Make adata for train/existing data.\n",
    "    # Make a column that contains bool values based on whether the sample_name holds one of the samples in the y_train..\n",
    "    adata.obs['contain_y_test'] = adata.obs['sampleID_label'].isin(y_test)\n",
    "    adata_test = adata[adata.obs['contain_y_test'] == True,:].copy()\n",
    "    \n",
    "    # Delete adata to free up memory.\n",
    "    #del adata\n",
    "    \n",
    "    print(\"Run PCA and UMAP on the adata_train.\")\n",
    "    # Run PCA and neighbour graph on the adata_train. \n",
    "    sc.pp.neighbors(adata_train, n_pcs = 30, n_neighbors = 20) \n",
    "    sc.tl.pca(adata_train)\n",
    "    if rep == 'X_umap':\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (UMAP).\")\n",
    "        sc.tl.umap(adata_train)\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='umap')\n",
    "    else:\n",
    "        print(\"Run sc.tl.ingest on the adata_test by the fit reducer (PCA).\")\n",
    "        sc.tl.ingest(adata_test, adata_train, embedding_method='pca')\n",
    "    \n",
    "    # Concatenate adata_train and adata_test into adata\n",
    "    adata_concat = adata_train.concatenate(adata_test, batch_categories=['ref', 'new'])\n",
    "    # Change the type of contain_y_train from bool to string.\n",
    "    adata_concat.obs['contain_y_train'] = adata_concat.obs['contain_y_train'].astype('str')\n",
    "    adata_concat.obs['contain_y_test'] = adata_concat.obs['contain_y_test'].astype('str')\n",
    "    # Save the adata_concat to a h5ad file.\n",
    "    print(f\"Saving {k}th adata in {rep_name} rep to a h5ad file...\")\n",
    "    adata_concat.write(f'../../data/k{k}_{rep_name}_adata_GSE_158055_COVID19.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_scanpy_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
